{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "565c2b4f",
      "metadata": {
        "id": "565c2b4f"
      },
      "source": [
        "## Assignment 2: Adversarial Training\n",
        "\n",
        "This assignment requires you to create adversarial examples. You will do adversarial training, i.e., train the model with sets of adversarial examples you generated and evaluate the performances of the model on test sets.\n",
        "\n",
        "### What is Adversarial Training?\n",
        "Adversarial training is a machine learning technique to improve models' robustness by training them on adversarial examples. Adversarial examples are input data that has been intentionally modified to cause the model to misclassify or produce an incorrect output.\n",
        "\n",
        "When a model is trained using adversarial examples, it becomes more resilient to adversarial attacks and is able to better identify and classify input data that may have been modified or corrupted. This may lead to improved performance of the model in real-world scenarios where the input data may not always be perfect.\n",
        "\n",
        "However, adversarial training can also have some negative impacts on ML models. For example, it can lead to overfitting, where the model becomes too specialized to the particular adversarial examples used in training and is unable to generalize well to new examples. Additionally, adversarial training can increase the computational requirements of training the model due to the need for generating adversarial examples.\n",
        "\n",
        "Overall, while adversarial training can improve the robustness of ML models, it is important to carefully consider its potential benefits and drawbacks and to evaluate the trade-offs in terms of model performance and computational requirements. The following are the steps involved in adversarial training:\n",
        "\n",
        "1. Generate adversarial examples: In the first step, we generate adversarial examples by perturbing the original data points in such a way that the modifications are small and not noticeable to humans but are enough to cause misclassification by the neural network.\n",
        "\n",
        "2. Train on adversarial examples: In the second step, we train the neural network on adversarial examples in addition to the original training data. This helps to improve the network's ability to recognize and classify adversarial examples correctly.\n",
        "\n",
        "3. Evaluate performance: In the third step, we evaluate the performance of the network on both the original and adversarial test data. This helps to determine if the adversarial training has improved the network's robustness against adversarial attacks.\n",
        "\n",
        "Overall, adversarial training is a powerful technique that can help improve the security and reliability of deep neural networks.\n",
        "\n",
        "In this Homework, you will run different adversarial training algorithms on the ResNet18 model with the adversarial examples, and evaluating the model performances on test data. The goal is to get experience in generating adversarial examples and train the model with these examples, i.e., adversarial training.\n",
        "\n",
        "We have provided the model architecture ($\\texttt{model.py}$) and some pre-defined functions ($\\texttt{utils.py}$) so you can import and use them directly in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a91b0d3",
      "metadata": {
        "id": "6a91b0d3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "from model import ResNet18\n",
        "from utils import trades_loss, mixup_data, mixup_criterion, make_dataloader, eval_test\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d7058cd",
      "metadata": {
        "id": "3d7058cd"
      },
      "source": [
        "### Q1 (20 points)\n",
        "Use the following parameters to define the LinfPGDAttack():\n",
        "\n",
        "- Epsilon: 8/255\n",
        "- PGD Steps: 10\n",
        "- PGD Step Size: 0.003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7919023a",
      "metadata": {
        "id": "7919023a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LinfPGDAttack(nn.Module):\n",
        "    def __init__(self, model, epsilon, steps=10, step_size=0.003):\n",
        "        super(LinfPGDAttack, self).__init__()\n",
        "        self.model = model\n",
        "        self.epsilon = epsilon\n",
        "        self.steps = steps\n",
        "        self.step_size = step_size\n",
        "\n",
        "    def perturb(self, x_natural, y, device='cuda'):\n",
        "        \"\"\"\n",
        "        Computes the gradient of the cross-entropy loss with respect to the input\n",
        "        image `x_adv` and updates the image based on the gradient direction. The\n",
        "        perturbation is clipped to ensure it stays within a specified epsilon range\n",
        "        and is finally clamped to ensure pixel values are valid.\n",
        "\n",
        "        The resulting perturbed image is returned.\n",
        "        \"\"\"\n",
        "        # *********** Your code starts here ***********\n",
        "        attacked = x_natural.clone().detach()\n",
        "        attacked.to(device)\n",
        "        attacked.requires_grad = True\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        for _ in range(self.steps):\n",
        "            output = self.model(attacked)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            gradient_sign = attacked.grad.sign()\n",
        "            attacked.grad.zero_()\n",
        "            attacked = attacked + self.step_size * gradient_sign\n",
        "            attacked = torch.max(torch.min(attacked, x_natural + self.epsilon), x_natural - self.epsilon)\n",
        "            attacked = attacked.clamp(0, 255)\n",
        "            attacked = attacked.clone().detach()\n",
        "            attacked.to(device)\n",
        "            attacked.requires_grad = True\n",
        "        # *********** Your code ends here *************\n",
        "        return attacked\n",
        "\n",
        "    def forward(self, x_natural, y, device='cuda'):\n",
        "        x_adv = self.perturb(x_natural, y, device)\n",
        "        return x_adv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2edaaf55",
      "metadata": {
        "id": "2edaaf55"
      },
      "source": [
        "There are many implementations of adversarial training; in this assignment, we ask you to evalaute which training algorithm can make the model more robust to LinfPGDAttack()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "835b7b4d",
      "metadata": {
        "id": "835b7b4d"
      },
      "outputs": [],
      "source": [
        "def train_ep(model, train_loader, mode, pgd_attack, optimizer, criterion, epoch, batch_size):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        if mode == 'natural':\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        elif mode == 'adv_train': # [Ref] https://arxiv.org/abs/1706.06083\n",
        "            model.eval()\n",
        "            adv_x = pgd_attack(inputs, targets)\n",
        "            model.train()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(adv_x)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        elif mode == 'adv_train_trades': # [Ref] https://arxiv.org/abs/1901.08573\n",
        "            optimizer.zero_grad()\n",
        "            loss = trades_loss(model=model, x_natural=inputs, y=targets, optimizer=optimizer)\n",
        "\n",
        "        elif mode == 'adv_train_mixup': # [Ref] https://arxiv.org/abs/1710.09412\n",
        "            model.eval()\n",
        "            benign_inputs, benign_targets_a, benign_targets_b, benign_lam = mixup_data(inputs, targets)\n",
        "            adv_x = pgd_attack(inputs, targets)\n",
        "            adv_inputs, adv_targets_a, adv_targets_b, adv_lam = mixup_data(adv_x, targets)\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            benign_outputs = model(benign_inputs)\n",
        "            adv_outputs = model(adv_inputs)\n",
        "            loss_1 = mixup_criterion(criterion, benign_outputs, benign_targets_a, benign_targets_b, benign_lam)\n",
        "            loss_2 = mixup_criterion(criterion, adv_outputs, adv_targets_a, adv_targets_b, adv_lam)\n",
        "\n",
        "            loss = (loss_1 + loss_2) / 2\n",
        "\n",
        "        else:\n",
        "            print(\"No training mode specified.\")\n",
        "            raise ValueError()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
        "                epoch, (batch_idx + 1) * len(inputs), len(train_loader) * batch_size,\n",
        "                       100. * (batch_idx + 1) / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed00bf9c",
      "metadata": {
        "id": "ed00bf9c"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, pgd_attack,\n",
        "          mode='natural', epochs=25, batch_size=256, learning_rate=0.1, momentum=0.9, weight_decay=2e-4,\n",
        "          checkpoint_path='model1.pt'):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "    best_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        # training\n",
        "        train_ep(model, train_loader, mode, pgd_attack, optimizer, criterion, epoch, batch_size)\n",
        "        # evaluate clean accuracy\n",
        "        test_loss, test_acc = eval_test(model, val_loader, device)\n",
        "        # remember best acc@1 and save checkpoint\n",
        "        is_best = test_acc > best_acc\n",
        "        best_acc = max(test_acc, best_acc)\n",
        "        # save checkpoint if is a new best\n",
        "        if is_best:\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "        print('================================================================')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ff637f3",
      "metadata": {
        "id": "6ff637f3"
      },
      "source": [
        "### Q2 (40 points)\n",
        "Use the four training modes (\"natural\", \"adv_train\", \"adv_train_trades\", and \"adv_train_mixup\") to obtain four models, and save them as $\\texttt{model1.pt}$, $\\texttt{model2.pt}$, $\\texttt{model3.pt}$, and $\\texttt{model4.pt}$, respectively.\n",
        "\n",
        "When calculating your losses, you may encounter Nan. In this case, you may consider adjusting the `learning rate` to solve the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1d19e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1d19e5",
        "outputId": "c946a3c1-fa5c-4396-c13c-0acbeb88a23d",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 72516926.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# define parameters\n",
        "batch_size = 256\n",
        "data_path = \"../data\" # directory of the data\n",
        "epsilon = 8/255\n",
        "steps = 10\n",
        "epochs = 25\n",
        "# create data loader\n",
        "train_loader, val_loader = make_dataloader(data_path, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ce821e",
      "metadata": {
        "id": "f7ce821e"
      },
      "outputs": [],
      "source": [
        "training_mode = \"natural\"\n",
        "# Define Model and Launch Training (Define Adversary If You Need It)\n",
        "model1 = ResNet18()\n",
        "model1.to(device)\n",
        "train(model1, train_loader, val_loader, LinfPGDAttack(model1, epsilon), training_mode, epochs, checkpoint_path = \"model1.pt\")\n",
        "# Write your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e90e8ee",
      "metadata": {
        "id": "7e90e8ee"
      },
      "outputs": [],
      "source": [
        "training_mode = \"adv_train\"\n",
        "# Define Model and Launch Training (Define Adversary If You Need It)\n",
        "model2 = ResNet18().to(device)\n",
        "train(model2, train_loader, val_loader, LinfPGDAttack(model2, epsilon), training_mode, epochs, checkpoint_path = \"model2.pt\")\n",
        "# Write your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a04ef0",
      "metadata": {
        "id": "a4a04ef0"
      },
      "outputs": [],
      "source": [
        "training_mode = \"adv_train_trades\"\n",
        "# Define Model and Launch Training (Define Adversary If You Need It)\n",
        "model3 = ResNet18()\n",
        "model3.to(device)\n",
        "model3.load_state_dict(torch.load(os.getcwd() + \"/model1.pt\"))\n",
        "train(model3, train_loader, val_loader, LinfPGDAttack(model3, epsilon), training_mode, epochs, checkpoint_path = \"model3.pt\")\n",
        "# Write your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5036a9f",
      "metadata": {
        "id": "b5036a9f"
      },
      "outputs": [],
      "source": [
        "training_mode = \"adv_train_mixup\"\n",
        "# Define Model and Launch Training (Define Adversary If You Need It)\n",
        "model4 = ResNet18()\n",
        "model4.to(device)\n",
        "model4.load_state_dict(torch.load(os.getcwd() + \"/model1.pt\"))\n",
        "train(model4, train_loader, val_loader, LinfPGDAttack(model4, epsilon), training_mode, epochs, checkpoint_path = \"model4.pt\")\n",
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cpl5qpfSH_Fx",
      "metadata": {
        "id": "cpl5qpfSH_Fx"
      },
      "source": [
        "In the following file, I am loading models because they were not trained from this file, so I can't use their instances"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a009caec",
      "metadata": {
        "id": "a009caec"
      },
      "source": [
        "### Q3 (20 points)\n",
        "Use eval_robust() to evaluate each model's robustness against LinfPGDAttack()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8a3ad6",
      "metadata": {
        "id": "7d8a3ad6"
      },
      "outputs": [],
      "source": [
        "from utils import eval_robust\n",
        "import os\n",
        "# *********** Your code starts here ***********\n",
        "checkpoint = torch.load(os.getcwd() + \"/model1.pt\")\n",
        "model1 = ResNet18()\n",
        "model1.load_state_dict(checkpoint)\n",
        "model1.to(device)\n",
        "model1.load_state_dict(torch.load(os.getcwd() + \"/model1.pt\"))\n",
        "adversary = LinfPGDAttack(model1, epsilon)\n",
        "robust_loss, robust_acc = eval_robust(model1, val_loader, adversary)\n",
        "# *********** Your code ends here *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c3bea2",
      "metadata": {
        "id": "97c3bea2"
      },
      "outputs": [],
      "source": [
        "# *********** Your code starts here ***********\n",
        "checkpoint = torch.load(os.getcwd() + \"/model2.pt\")\n",
        "model = ResNet18()\n",
        "model.load_state_dict(checkpoint)\n",
        "model.to(device)\n",
        "adversary = LinfPGDAttack(model, epsilon)\n",
        "robust_loss, robust_acc = eval_robust(model, val_loader, adversary)\n",
        "# *********** Your code ends here *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56863557",
      "metadata": {
        "id": "56863557"
      },
      "outputs": [],
      "source": [
        "# *********** Your code starts here ***********\n",
        "checkpoint = torch.load(os.getcwd() + \"/model3.pt\")\n",
        "model = ResNet18()\n",
        "model.load_state_dict(checkpoint)\n",
        "model.to(device)\n",
        "adversary = LinfPGDAttack(model, epsilon)\n",
        "robust_loss, robust_acc = eval_robust(model, val_loader, adversary)\n",
        "# *********** Your code ends here *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf7ba88",
      "metadata": {
        "id": "8bf7ba88"
      },
      "outputs": [],
      "source": [
        "# *********** Your code starts here ***********\n",
        "checkpoint = torch.load(os.getcwd() + \"/model4.pt\")\n",
        "model = ResNet18()\n",
        "model.load_state_dict(checkpoint)\n",
        "model.to(device)\n",
        "adversary = LinfPGDAttack(model, epsilon)\n",
        "robust_loss, robust_acc = eval_robust(model, val_loader, adversary)\n",
        "# *********** Your code ends here *************"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c60a88c",
      "metadata": {
        "id": "3c60a88c"
      },
      "source": [
        "### Q4 (10 points)\n",
        "Visualize 10 adversarial examples from (with ground truth labels and model's predictions) from the model having best robust accuarcy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311b616a",
      "metadata": {
        "id": "311b616a"
      },
      "outputs": [],
      "source": [
        "# *********** Your code starts here ***********\n",
        "import matplotlib.pyplot as plt\n",
        "assuming model4 has the bes accuracy. I ran out of training computers, and was not able to continue training all the models\n",
        "checkpoint = torch.load(os.getcwd() + \"/model4.pt\")\n",
        "best_model = ResNet18()\n",
        "best_model.load_state_dict(checkpoint)\n",
        "best_model.to(device)\n",
        "adversary = LinfPGDAttack(best_model, epsilon)\n",
        "for index, (input, label)in enumerate(val_loader):\n",
        "  count = 0\n",
        "  for image, label in zip(input, label):\n",
        "    image = adversary(image, label)\n",
        "    plt.imshow(image.T)\n",
        "    count += 1\n",
        "    if count >= 9:\n",
        "      break\n",
        "  break\n",
        "# *********** Your code ends here *************"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b6dfa2",
      "metadata": {
        "id": "d3b6dfa2"
      },
      "source": [
        "### Q5 (10 points)\n",
        "Which adversarial training algorithm achieves the best robust accuracy in only 25 training epochs? Why do you think that adversarial training algorithm outperforms others? Do you encounter any difficulties when you implement this assignment?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d15618d3",
      "metadata": {
        "id": "d15618d3"
      },
      "source": [
        "**NOTE:** I did not train for 25 epochs. For every model I trained for around 10 epochs. Also, I reached my GPU usage at Google Colab, so I couldn't run the robustness tests. So I am going to do analogies based on the algorithms themselves, and what the content learned in class.\n",
        "\n",
        " **The best algorithm:** Should be between TRADES and adv_train_mixup. This is because, on the top of adversarial training, adv_train_mix up includes the regularization methods which can improve the accuracy of the model, while TRADES maintains the balance between achieveing high accuracy on clean data, and maintaining the robustness of the model on adversarial attacks.\n",
        "\n",
        "\n",
        "**Reasons**\n",
        "\n",
        "At the top of making adversarial attacks, the algorithms includes data augmentation techniques which reduces overfitting, and improves robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412124b3",
      "metadata": {
        "id": "412124b3"
      },
      "source": [
        "## Submission Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ef9ffc6",
      "metadata": {
        "id": "7ef9ffc6"
      },
      "source": [
        "Please submit this  to Canvas, as well as results, as per instructions.\n",
        "Please compress `First_Middle_Last_HW1/` into one zip file with the name `First_Middle_Last_HW1.zip` before uploading it to Canvas. The directory contains your notebook and four model checkpoints. As listed below:\n",
        "\n",
        "- $\\texttt{Assignment_2.ipynb}$: your code\n",
        "- $\\texttt{model1.pt}$: your model checkpoint with *natural training*\n",
        "- $\\texttt{model2.pt}$: your model checkpoint with *adv_train* training\n",
        "- $\\texttt{model3.pt}$: your model checkpoint with *adv_train_trades* training\n",
        "- $\\texttt{model4.pt}$: your model checkpoint with *adv_train_mixup* training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceec7b76",
      "metadata": {
        "id": "ceec7b76"
      },
      "source": [
        "## Academic Integrity\n",
        "\n",
        "This homework assignment must be done individually. Sharing code or model specifications is strictly prohibited. Homework discussions are allowed only on Piazza, according to the policy outlined on the course web page: [https://canvas.dartmouth.edu/courses/63219](https://canvas.dartmouth.edu/courses/63219). You are not allowed to search online for auxiliary software, reference models, architecture specifications, or additional data to solve the homework assignment. Your submission must be entirely your own work. That is, the code and the answers that you submit must be created, typed, and documented by you alone, based exclusively on the materials discussed in class, and released with the homework assignment. You can obviously consult the class slides posted in Canvas, your lecture notes, and the textbook. Important: the models you will submit for this homework assignment must be\n",
        "trained exclusively on the specified data provided with this assignment. You can, of course, play with other datasets in your spare time. These rules will be strictly enforced, and any violation will be treated seriously."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
